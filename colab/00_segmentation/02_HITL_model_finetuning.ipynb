{"cells":[{"cell_type":"markdown","metadata":{"id":"h5T_9__1mAfq"},"source":["# Description\n","*author:* Vina My Pham<br>\n","*supervisor:* Robin van der Weide<br>\n","*project:* MSc internship project<br>\n","<br>\n","*date:* January 15 - July 19, 2024<br>\n","*host:* Kind group, Hubrecht Institute<br>\n","*university:* Bioinformatics, Wageningen University & Research<br>\n","\n","---\n","\n","Notebook to finetune a pre-trained *cellpose* model with a human-in-the-loop approach (HITL) [1].\n","\n","The method constitutes of the following steps:\n","  1. Running the model on an image\n","  2. Refining the predictions to match the required segmentation style.\n","  3. Adding the image and refined masks to the training data.\n","  4. Retraining the model on the training data\n","  5. Repeat steps 1-4 until retrained model has required performance.\n","\n","![](https://drive.google.com/uc?export=view&id=1dUD8rGO2QQnSqrhVBRCREPPpfHZ1xBAy)\n","\n","**References**\n","1. Pachitariu, M., Stringer, C. Cellpose 2.0: how to train your own model. Nat Methods 19, 1634â€“1641 (2022). https://doi.org/10.1038/s41592-022-01663-4"]},{"cell_type":"markdown","metadata":{"id":"W2C2rBgNh0Wl"},"source":["# Notebook initialisation\n","**Description:** This block contains the code for the set-up of the notebook.\n","\n","0. mount the notebook to the drive\n","1. install required dependencies with a `requirements.txt` file\n","2. import python modules\n","3. define custom classes and functions\n","4. check GPU connection\n","\n","**Instructions:**\n","1. Select the wanted initialisation settings.\n","2. Execute the code at the beginning of the run.\n","\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"cellView":"form","id":"p3WurfqzhxF8","executionInfo":{"status":"ok","timestamp":1708948987892,"user_tz":-60,"elapsed":246,"user":{"displayName":"Vina My","userId":"04911422721587392535"}}},"outputs":[],"source":["#@markdown ## Initialisation settings\n","mount_drive = True #@param {type:\"boolean\"}\n","#@markdown <br>\n","pip_install = True #@param {type:\"boolean\"}\n","pip_requirements_path = \"/content/gdrive/MyDrive/msc-internship_HI_2024_vmp/01_notebooks/colab_requirements.txt\" #@param {type:\"string\"}\n","#@markdown <br>\n","import_pkg = True #@param {type:\"boolean\"}\n","#@markdown <br>\n","use_gpu = False #@param {type:\"boolean\"}"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":229165,"status":"ok","timestamp":1708949219847,"user":{"displayName":"Vina My","userId":"04911422721587392535"},"user_tz":-60},"id":"wzI_kSFUkcTw","outputId":"17622eb3-c700-4144-a20e-cabcc2995a61","cellView":"form"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","Succesfully installed requirements with pip\n","Succesfully imported packages\n"]}],"source":["#@markdown [code: imports - runtime: ~3m23s]\n","if mount_drive:\n","  from google.colab import drive\n","  drive.mount('/content/gdrive', force_remount=True)\n","\n","if pip_install:\n","  import subprocess\n","  subprocess.run(['apt-get', 'install', '-y', 'libcairo2-dev'], check=True)\n","  subprocess.run(['pip', 'install', '-r', pip_requirements_path], check=True)\n","  print(\"Succesfully installed requirements with pip\")\n","\n","if import_pkg:\n","  import os\n","  import json\n","  import copy\n","  from datetime import datetime\n","  from collections import defaultdict, Counter\n","  from tifffile import imwrite\n","  from cellpose.io import imread, masks_flows_to_seg, save_masks\n","  from cellpose import core, utils, plot, models\n","  import matplotlib.pyplot as plt\n","  import numpy as np\n","\n","  print(\"Succesfully imported packages\")"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":393,"status":"ok","timestamp":1708949297343,"user":{"displayName":"Vina My","userId":"04911422721587392535"},"user_tz":-60},"id":"zU73rFZlkf93","cellView":"form"},"outputs":[],"source":["#@markdown [code: classes]\n","class Slice:\n","  \"\"\"Class for slices\n","\n","  Attributes:\n","    name (str): Name of the slice\n","    img_path (str): Absolute path to the image file\n","    mask_path (str): Absolute path to the mask file\n","\n","  Methods:\n","    matrix(matrix_type: str) -> np.ndarray:\n","        Retrieve the image or mask of the slice as a matrix\n","\n","    show(mode: str = \"\",\n","         seg_channel: int = 2,\n","         subplot_size: tuple = (5,5)) -> None:\n","        Display the image and/or mask of the slice using matplotlib\n","  \"\"\"\n","  def __init__(self, name: str, img_path: str, mask_path: str):\n","    \"\"\"Initialise object\n","\n","    Args:\n","      name (str): Name of the slice\n","      img_path (str): Absolute path to the image file\n","      mask_path (str): Absolute path to the mask file\n","    \"\"\"\n","    self.name = name\n","    self.img_path = img_path\n","    self.mask_path = mask_path\n","\n","  def matrix(self, matrix_type: str):\n","    \"\"\"Retrieve the image or masks of the slice as a matrix\n","\n","    Args:\n","        matrix_type (str): \"img\" or \"mask\"\n","\n","    Returns:\n","        np.ndarray: Matrix representing the image or mask\n","                    if image: shape = (n channels x nX x nY)\n","    \"\"\"\n","    if matrix_type not in [\"img\", \"mask\"]:\n","      raise ValueError(f\"matrix type `{matrix_type}` not recognised. \")\n","\n","    path = {\"img\":self.img_path, \"mask\":self.mask_path}.get(matrix_type)\n","    matrix = imread(path)\n","\n","    if matrix_type == \"img\":\n","      channel_idx = matrix.shape.index(min(matrix.shape))\n","\n","      if channel_idx == 1:\n","        matrix = matrix.transpose(1,0,2) #channel as first element\n","      if channel_idx == 2:\n","        matrix = matrix.transpose(2,0,1)\n","\n","    if matrix_type == \"mask\":\n","      matrix = reassign_ids(matrix)\n","\n","    return matrix\n","\n","  def show(self,\n","           mode: str = \"\",\n","           seg_channel: int = 2,\n","           subplot_size: tuple = (5,5)) -> None:\n","    \"\"\"Display the image and mask using matplotlib.\n","\n","    Args:\n","        mode (str): Visualisation mode. Valid options:\n","                    \"img\": the original image (separate channels + merged)\n","                    \"mask\". the original image and mask outlines.\n","                    \"\": both \"img\" and \"mask\"\n","                    Default: \"\"\n","        seg_channel (int): channel used for segmentation - R:1, G:2, B:3.\n","                           Default: 2\n","        subplot_size (tuple): Size of the subplot_size (width, height).\n","                              Default: (5, 5)\n","    \"\"\"\n","    if mode not in (\"\", \"mask\", \"img\"):\n","      error_msg = f\"Visualisation mode `{mode}` not recognised. Valid \" +\\\n","                  \"options are ['', 'img', 'mask']\"\n","      raise ValueError(error_msg)\n","\n","    img_matrix = self.matrix(\"img\")\n","    merged_matrix = np.dstack((img_matrix[0,:,:], img_matrix[1,:,:], img_matrix[2,:,:]))\n","\n","    #plot image (separate channels, merged)\n","    if mode in (\"\", \"img\"):\n","      n_subplots = img_matrix.shape[0]+1\n","\n","      figsize = (subplot_size[0]*n_subplots, subplot_size[1])\n","      fig, axes = plt.subplots(1, n_subplots, figsize=figsize)\n","\n","      #separate channels\n","      for i in range(0, n_subplots-1):\n","        axes[i].imshow(img_matrix[i,:,:], cmap=plt.cm.gray)\n","        axes[i].axis(\"off\")\n","        axes[i].set_title(f\"channel {i+1}\")\n","\n","      #merged\n","      axes[n_subplots-1].imshow(merged_matrix)\n","      axes[n_subplots-1].axis(\"off\")\n","      axes[n_subplots-1].set_title(\"Merged\")\n","\n","      fig.suptitle(f\"{self.name} - channels\")\n","      fig.tight_layout()\n","      plt.show();\n","\n","    #plot mask (original image, outlines)\n","    if mode in (\"\", \"mask\"):\n","      figsize = (subplot_size[0]*3, subplot_size[1])\n","      fig, axes = plt.subplots(1, 3, figsize=figsize)\n","\n","      #original image\n","      axes[0].imshow(merged_matrix)\n","      axes[0].set_title(\"Merged\")\n","      axes[0].axis(\"off\")\n","\n","      #channel used to segment\n","      axes[1].imshow(img_matrix[seg_channel-1,:,:], cmap=plt.cm.gray)\n","      axes[1].set_title(f\"Channel {seg_channel}\")\n","      axes[1].axis(\"off\")\n","\n","      #outlines\n","      outlines = utils.outlines_list(self.matrix(\"mask\"))\n","      axes[2].imshow(img_matrix[seg_channel-1,:,:], cmap=plt.cm.gray)\n","      for o in outlines:\n","          axes[2].plot(o[:,0], o[:,1], color='r', linewidth=0.7)\n","      axes[2].axis(\"off\")\n","      axes[2].set_title(\"Masks\")\n","\n","      fig.suptitle(f\"{self.name} - annotation\")\n","      fig.tight_layout()\n","      plt.show();\n","\n","    return None"]},{"cell_type":"code","execution_count":16,"metadata":{"cellView":"form","id":"lv8QtrKEWurU","executionInfo":{"status":"ok","timestamp":1708949905441,"user_tz":-60,"elapsed":232,"user":{"displayName":"Vina My","userId":"04911422721587392535"}}},"outputs":[],"source":["#@markdown [code: functions]\n","#_output\n","def write_json(parameters: dict, save_dir: str,\n","               output_name: str = \".model_params.JSON\",\n","               overwrite=False, verbose=True) -> str:\n","    \"\"\"Write settings to a JSON file\n","\n","    Args:\n","        parameters (dict): Settings to be written to the JSON file\n","        save_dir (str): The directory path where the JSON file will be saved\n","        output_name (str): name of output file. Default: \".model_params.JSON\"\n","        overwrite (bool, optional): Overwrite if file exists. Default: False\n","        verbose (bool, optional): Print verbose. Default: True\n","\n","    Returns:\n","        str: The path where the JSON file was saved\n","\n","    Raises:\n","        FileExistsError: If a file with `output_name` in `save_dir` already\n","                         exists, and `overwrite` is set to False\n","    \"\"\"\n","    if os.path.exists(save_dir) == False:\n","      os.makedirs(save_dir)\n","\n","    json_path = os.path.join(save_dir, output_name)\n","\n","    if os.path.exists(json_path) and not overwrite:\n","        raise FileExistsError(f\"File '{json_path}' exists and `overwrite` has\" +\n","                              f\" been set to {overwrite}\")\n","\n","    with open(json_path, 'w') as outfile_obj:\n","        json.dump(parameters, outfile_obj, indent=4)\n","\n","    if verbose:\n","        print(f\"All settings written to {json_path}\")\n","\n","    return json_path\n","\n","#_utilities\n","def check_gpu_connection(use_gpu: bool) -> None:\n","    \"\"\"Reports the details on GPU connection\n","\n","    Args:\n","        use_gpu (bool): Whether to use the GPU for the script\n","\n","    Returns:\n","        None\n","\n","    Raises:\n","        GPUConnectionError: If the runtime type does not match the connection\n","        settings\n","    \"\"\"\n","    class GPUConnectionError(Exception):\n","        def __init__(self, message):\n","            self.message = message\n","\n","    if core.use_gpu() != use_gpu:\n","      raise GPUConnectionError(f\"Connection type (`{core.use_gpu()}`) does \" +\n","                               f\"not match connection settings (`{use_gpu}`).\"+\n","                               \"\\nPlease check the hardware type in the Colab\"+\n","                               \" Notebook settings.\")\n","\n","    if core.use_gpu():\n","      !nvidia-smi\n","\n","    return None\n","\n","#_segmentation\n","def run_cellpose_model(slice_obj: Slice,\n","                       save_dir: str,\n","                       model: models.CellposeModel,\n","                       run_args: dict = {},\n","                       verbose: bool = True) -> None:\n","    \"\"\"Wrapper function for CellposeModel.eval()\n","\n","    Args:\n","      img (np.ndarray): matrix representation of an image to segment. shape:\n","                        (n channels x nX x nY)\n","      model(cellpose.models.CellposeModel): the cellpose model\n","      run_args (dict): arguments to give to model.eval(). {param (str) : arg}\n","                      if not specified, default will be used\n","      save_dir (None or str): if None: Results are not saved (default)\n","                              if str: path to save the _seg.npy file\n","\n","    Returns:\n","      str - path to masks .tif\n","    \"\"\"\n","    #init\n","    img = slice_obj.matrix(\"img\")\n","    img_name = slice_obj.name\n","\n","    #run model\n","    masks, flows, styles = model.eval(\n","        img,\n","        diameter=run_args.get('diameter', 30.0),\n","        flow_threshold=run_args.get('flow_threshold', 0.4),\n","        cellprob_threshold=run_args.get('cellprob_threshold', 0.0),\n","        channels=run_args.get('channels', [0, 0])\n","        )\n","\n","    #save model\n","    file_name = f\"{save_dir}/{img_name}\"\n","    masks_flows_to_seg(\n","        img, masks, flows, run_args.get('diameter', 30.0),\n","        file_name, run_args.get('channels', [0, 0])\n","      )\n","    if verbose: print(f\"_seg.npy file saved as {file_name}_predicted_seg.npy\")\n","\n","    #save masks\n","    mask_path = os.path.join(save_dir, f\"{file_name}_predicted_masks.tif\")\n","    imwrite(mask_path, masks)\n","    if verbose: print(f\"Predicted masks have been saved in {mask_path}\")\n","\n","    return mask_path\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L_lxEx5_kJbf","cellView":"form"},"outputs":[],"source":["#@markdown ###GPU status\n","#@markdown *Note: To change hardware type: `Runtime` >> `Change runtime type` >> `Hardware accelerator`*\n","print(f\"GPU usage enabled: {use_gpu}\")\n","check_gpu_connection(use_gpu)"]},{"cell_type":"markdown","metadata":{"id":"68qj5R82WjFb"},"source":["## Input/output path specification"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"pT51yZrFd6M0","executionInfo":{"status":"ok","timestamp":1708950917726,"user_tz":-60,"elapsed":232,"user":{"displayName":"Vina My","userId":"04911422721587392535"}},"cellView":"form"},"outputs":[],"source":["#@markdown **Test data - settings**\n","test_img_path = \"\" #@param {type:\"string\"}\n","test_mask_path = \"\" #@param {type:\"string\"}\n","test_img_name = \"\" #@param {type:\"string\"}\n","\n","#@markdown **Path to the main output directory**\n","main_save_dir = \"\" #@param {type:\"string\"}\n","main_save_dir = os.path.join(main_save_dir, \"\")"]},{"cell_type":"markdown","metadata":{"id":"CxpLvhU5zw-m"},"source":["# Main script"]},{"cell_type":"markdown","metadata":{"id":"9ZzdMDKeSrie"},"source":["## Inspection of test data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wfI7t2QFe5ws","cellView":"form"},"outputs":[],"source":["#@markdown [code block]\n","#@markdown 1. store test data in `test_obj` (Slice object)\n","#@markdown 2. display the test data (original image and masks)\n","\n","test_obj = Slice(test_img_name, test_img_path, test_mask_path)\n","print(f\"Test data has been stored with metadata:\\n\"+\n","      f\"\\tname: {test_obj.name}\\n\"+\n","      f\"\\timg_path: {test_obj.img_path}\\n\"+\n","      f\"\\tmask_path: {test_obj.mask_path}\")\n","\n","test_obj.show(subplot_size=(5,5), seg_channel=2)"]},{"cell_type":"markdown","metadata":{"id":"Vm9eNM5Dz5wt"},"source":["## Model finetuning"]},{"cell_type":"markdown","source":["### 0. init"],"metadata":{"id":"US4R15-SbB1J"}},{"cell_type":"code","source":["#@markdown\n","#@markdown - (if first time run) initialise `train_objs`, `save_dirs` and `model_names`\n","#@markdown - show pre-trained model names\n","try:\n","    train_objs\n","except NameError:\n","    train_objs, save_dirs, model_names = [[],[],[]]\n","    cellpose_models =  models.MODEL_NAMES\n","    print(\"Initialised train_objs, save_dirs, and model_names\")\n","\n","print(\"Available pre-trained models:\\n\\t\", \"\\n\\t \".join(cellpose_models))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p5Hp6tmiJrm5","executionInfo":{"status":"ok","timestamp":1708952111103,"user_tz":-60,"elapsed":258,"user":{"displayName":"Vina My","userId":"04911422721587392535"}},"outputId":"2a59a373-ef60-496a-e1d3-e36c2c47f12e","cellView":"form"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Available pre-trained models:\n","\t cyto\n","\t nuclei\n","\t tissuenet\n","\t livecell\n","\t cyto2\n","\t general\n","\t CP\n","\t CPx\n","\t TN1\n","\t TN2\n","\t TN3\n","\t LC1\n","\t LC2\n","\t LC3\n","\t LC4\n"]}]},{"cell_type":"code","source":["#@markdown **I/O set-up**\n","train_img_path = \"\" #@param {type:\"string\"}\n","train_img_name = \"\" #@param {type:\"string\"}\n","run_id = \"\" #@param {type:\"string\"}\n","overwrite = False #@param {type:\"boolean\"}\n","\n","#@markdown **Model settings: load**\n","#@markdown - `model_type`: pre-trained model name (str). Set to `None` if a custom model is used.\n","#@markdown - `pretrained_model_path`: path to custom model (str). Set to `False` if a pre-trained model is used.\n","model_type = None #@param {type:\"raw\"}\n","pretrained_model = False #@param {type:\"raw\"}\n","\n","gpu = False #@param {type:\"boolean\"}\n","net_avg = True #@param {type:\"boolean\"}\n","diam_mean = 30.0 #@param {type:\"number\"}\n","device = None #@param {type:\"raw\"}\n","residual_on = True #@param {type:\"boolean\"}\n","style_on = True #@param {type:\"boolean\"}\n","concatenation = False #@param {type:\"boolean\"}\n","nchan = 2 #@param {type:\"integer\"}\n","\n","#@markdown **Model settings: run**\n","channels = [2,0] #@param {type:\"raw\"}\n","flow_threshold = 0.4 #@param  {type:\"number\"}\n","mask_threshold = 0.0 #@param {type:\"number\"}\n","\n","#initialising run directory name\n","curr_datetime = datetime.now()\n","run_name = f\"run{run_id}_{curr_datetime.strftime('%Y%m%d-%H%M%S')}\"\n","save_dir = os.path.join(main_save_dir, run_name)\n","print(f\"Output will be saved in {save_dir}\")\n","\n","#writing to settings to a JSON file\n","model_args = {\n","        \"model_type\": model_type,\n","        \"pretrained_model\": pretrained_model,\n","        \"gpu\": gpu,\n","        \"net_avg\": net_avg,\n","        \"diam_mean\": diam_mean,\n","        \"device\": device,\n","        \"residual_on\": residual_on,\n","        \"style_on\": style_on,\n","        \"concatenation\": concatenation,\n","        \"nchan\": nchan  # Fill in the value for `nchan` here\n","    }\n","\n","run_args = {\"channels\":channels,\n","            \"flow_threshold\":flow_threshold,\n","            \"mask_threshold\":mask_threshold}\n","parameters = {\n","    \"Slice\": {\n","        \"name\": train_img_name,\n","        \"img_path\": train_img_path,\n","        \"mask_path\": \"\"\n","    },\n","    \"Model parameters\": model_args,\n","    \"Run parameters\": run_args\n","}\n","\n","write_json(parameters, save_dir, overwrite=overwrite, verbose=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","id":"2eltHyfhYtLO","executionInfo":{"status":"ok","timestamp":1708951979448,"user_tz":-60,"elapsed":235,"user":{"displayName":"Vina My","userId":"04911422721587392535"}},"outputId":"758e759b-f443-41d0-8473-c9d0f0087078"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Output will be saved in test_dir/run_20240226-125259\n","{'Slice': {'name': '', 'img_path': '', 'mask_path': ''}, 'Model parameters': {'model_type': None, 'pretrained_model': False, 'gpu': False, 'net_avg': True, 'diam_mean': 30.0, 'device': None, 'residual_on': True, 'style_on': True, 'concatenation': False, 'nchan': 2}, 'Run parameters': {'channels': [2, 0], 'flow_threshold': 0.4, 'mask_threshold': 0.0}}\n"]}]},{"cell_type":"markdown","source":["###0. Load the model"],"metadata":{"id":"fURDhGC_YObn"}},{"cell_type":"code","source":["#@markdown [code: models.CellposeModel]\n","model = models.CellposeModel(\n","    gpu=model_args.get('gpu', False),\n","    pretrained_model=model_args.get('pretrained_model', False),\n","    model_type=model_args.get('model_type', None),\n","    net_avg=model_args.get('net_avg', True),\n","    diam_mean=model_args.get('diam_mean', 30.0),\n","    device=model_args.get('device', None),\n","    residual_on=model_args.get('residual_on', True),\n","    style_on=model_args.get('style_on', True),\n","    concatenation=model_args.get('concatenation', False),\n","    nchan=model_args.get('nchan', 2)\n","    )"],"metadata":{"id":"JsEf7-KoYRXW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 1. Run the model on an input slice"],"metadata":{"id":"06rnttQnmEsL"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"rGwzI0nN91XS"},"outputs":[],"source":["next_train_obj = Slice(name=train_img_name, img_path=train_img_path, mask_path=\"\")\n","\n","mask_path = run_cellpose_model(slice_obj = next_train_obj,\n","                   save_dir = save_dir,\n","                   model = model,\n","                   run_args = run_args)\n","\n","#@markdown **5. Store results (SliceObject, model)**\n","slice_predicted = Slice(name=f\"{next_train_obj.name}_predicted\",\n","                        img_path=next_train_obj.img_path,\n","                        mask_path=mask_path)"]},{"cell_type":"markdown","source":["### 2. Manually refining the masks\n","1. load _seg.npy in the GUI\n","2. manually refine\n","3. save masks\n","4. convert to tif"],"metadata":{"id":"RnxaA4n9u-WZ"}},{"cell_type":"markdown","source":["### 3. Compare predictions with manually refined masks."],"metadata":{"id":"EwDwv3pkmaOc"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"t4QgpQq0Eakt","cellView":"form"},"outputs":[],"source":["#@markdown **Input**\n","img_mask_refined = \"\" #@param {type:\"string\"}\n","\n","#@markdown <hr>\n","\n","#@markdown 1. Add manually refined masks to the Slice and `train_objs`\n","next_train_obj.mask_path = img_mask_refined\n","train_objs.append(next_train_obj)\n","\n","#@markdown 2. Compare predicted with manual refined masks\n","slice_predicted.show('mask')\n","next_train_obj.show('mask')"]},{"cell_type":"markdown","source":["### 4. Run the model on the golden standard\n","- compare with golden standard segmentation"],"metadata":{"id":"MuUJUQP4muI0"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"HitlDNN9Rbbo"},"outputs":[],"source":["#@markdown run on golden standard\n","#run models on the golden standard\n","mask_path = run_cellpose_model(slice_obj = test_obj,\n","                  save_dir = save_dir,\n","                  model = model,\n","                  run_args = run_args)\n","\n","#store as a Slice object\n","test_slice_predicted = Slice(name=f\"{test_obj.name}_predicted\",\n","                        img_path=test_obj.img_path,\n","                        mask_path=mask_path)\n","\n","test_results.append(test_slice_predicted)\n","test_slice_predicted.show('mask')\n","test_obj.show('mask')"]},{"cell_type":"markdown","metadata":{"id":"Py4GP8apMPBx"},"source":["### Train the model\n","- https://cellpose.readthedocs.io/en/latest/api.html#cellpose.models.CellposeModel.train\n","\n","- retrain the previously loaded model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SgYimTLy_dY8"},"outputs":[],"source":["#@markdown Available training images:\n","print(\"id\\tslice_name\\tmask_path\")\n","for idx, train_obj in enumerate(train_objs):\n","  print(f\"{idx}\\t{train_obj.name}\\t{train_obj.mask_path.split('/')[-1]}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yb74ILOJ_xv4","cellView":"form"},"outputs":[],"source":["#current_train_obj = train_objs[0]\n","#current_test_obj = test_objs[0]\n","#@markdown <br>**Data settings**<hr>\n","selected_train_obj_ids = [0] #@param {type:\"raw\"}\n","\n","#@markdown <br>**Training settings**<hr>\n","#pretrained_model_path = \"/content/gdrive/MyDrive/msc-internship_HI_2024_vmp/02_results/03.1_finetuning/iteration_01/models/cyto2_retrained\" #@param {type:\"raw\"}\n","n_epochs = 100  #@param {type:\"integer\"}\n","learning_rate = 0.1  #@param {type:\"number\"}\n","momentum = 0.9  #@param {type:\"number\"}\n","sgd = True  #@param {type:\"boolean\"}\n","weight_decay = 0.0001  #@param {type:\"number\"}\n","batch_size = 8  #@param {type:\"integer\"}\n","nimg_per_epoch = None  #@param {type:\"raw\"}\n","rescale = True  #@param {type:\"boolean\"}\n","min_train_masks = 1  #@param {type:\"integer\"}\n","normalize = True  #@param {type:\"boolean\"}\n","\n","#@markdown <br>**Output settings**<hr>\n","save_every = 100  #@param {type:\"integer\"}\n","save_each = False #@param {type:\"boolean\"}\n","model_name = \"retrained\" #@param {type:\"string\"}\n","\n","#Data loading\n","selected_train_objs = [train_objs[idx] for idx in selected_train_obj_ids]\n","train_data = [sliceobj.matrix(\"img\") for sliceobj in selected_train_objs]\n","train_labels = [sliceobj.matrix(\"mask\") for sliceobj in selected_train_objs]\n","train_files = [sliceobj.name for sliceobj in selected_train_objs]\n","test_data = None\n","test_labels = None\n","test_files = None\n","\n","#Write parameters to a file\n","parameters = {\n","    \"n_epochs\": n_epochs, \"train_files\": train_files,\n","    \"test_files\": test_files, \"channels\": channels, \"normalize\": normalize,\n","    \"save_path\": save_dir, \"save_every\": save_every, \"save_each\": save_each,\n","    \"learning_rate\": learning_rate, \"momentum\": momentum,\n","    \"sgd\": sgd, \"weight_decay\": weight_decay, \"batch_size\": batch_size,\n","    \"nimg_per_epoch\": nimg_per_epoch, \"rescale\": rescale,\n","    \"min_train_masks\": min_train_masks, \"model_name\": model_name\n","    }\n","\n","write_json(parameters, save_dir, output_name=\".retrained_model_params.JSON\")\n","\n","save_dirs.append(save_dir)\n","model_names.append(model_name)\n"]},{"cell_type":"markdown","metadata":{"id":"0JikHMxB1N_m"},"source":["# Visualise all segmentations on golden standard (compilation)"]},{"cell_type":"code","source":["#loop through runs\n","for run_dir in os.listdir(main_save_dir):\n","  abs_run_dir_path = os.path.join(main_save_dir, run_dir)\n","  test_pred_mask_path = os.path.join(abs_run_dir_path, f\"{test_obj.name}_predicted_masks.tif\")\n","  plt.imshow(imread(test_obj.img_path))\n","\n","  outlines_pred = plot.outlines_list(imread(test_pred_mask_path))\n","  for o in outlines_pred:\n","    plt.plot(o[:,0], o[:,1], color='r')"],"metadata":{"id":"SlTUFOoRBI8K"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMeohjizZgFZ1/ewSz9+2ZH"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}